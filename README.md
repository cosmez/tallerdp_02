# Taller 02 - Estructura y Razonamiento en Modelos de Lenguaje

Este repositorio contiene material educativo completo para un taller sobre Large Language Models (LLMs), enfocado en aspectos fundamentales, implementaci√≥n pr√°ctica y uso avanzado de modelos de lenguaje.

## üìã Descripci√≥n del Proyecto

El taller est√° dise√±ado para proporcionar una comprensi√≥n profunda de los modelos de lenguaje, desde su estructura interna hasta su implementaci√≥n pr√°ctica usando APIs como Gemini y frameworks como HuggingFace. El contenido est√° organizado en m√≥dulos progresivos que cubren tanto conceptos te√≥ricos como ejercicios pr√°cticos.

## üóÇÔ∏è Estructura del Proyecto

### 1. Estructura Interna
**Carpeta: `1. Estructura interna/`**
- `1-Tokens.ipynb` - Introducci√≥n a la tokenizaci√≥n y manejo de tokens
- `2-Contexto.ipynb` - Comprensi√≥n del contexto en LLMs
- `3-Parametros.ipynb` - Par√°metros configurables de los modelos

### 2. Razonamiento Interno
**Carpeta: `2. Razonamiento Interno/`**
- `1-Razonamiento.ipynb` - C√≥mo razonan los LLMs internamente

### 3. Principios de Dise√±o de Prompts
**Carpeta: `3. Principios de dise√±o de prompts/`**
- `1-Prompting.ipynb` - T√©cnicas y mejores pr√°cticas para dise√±o de prompts

### 4. Formato de Conversaci√≥n
**Carpeta: `4. Formato Conversacion/`**
- `1-Conversacion.ipynb` - Manejo de conversaciones y formatos de di√°logo

### 5. Herramientas y Agentes
**Carpeta: `5. Herramientas/`**
- `1-Herramientas.ipynb` - Tool calling y uso de herramientas externas
- `2-Agente.ipynb` - Implementaci√≥n de agentes inteligentes

### 6. API de Gemini
**Carpeta: `6. Gemini/`**
- `1-Gemini.ipynb` - Integraci√≥n y uso avanzado de la API de Gemini

### 7. Contenido Extra
**Carpeta: `7. Extra/`**
- `Modelos locales y HuggingFace.ipynb` - Trabajo con modelos locales y HuggingFace
- `Runtimes,_Cuantizacion,_Ollama,_LM_Studio.ipynb` - Runtimes locales, cuantizaci√≥n y herramientas

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos
- Python 3.8 o superior
- Jupyter Notebook o JupyterLab
- Acceso a API de Google Gemini (API Key requerida)

### Instalaci√≥n

1. **Clonar el repositorio:**
```bash
git clone <repository-url>
cd tallerdp_02
```

2. **Crear entorno virtual (recomendado):**
```bash
python -m venv venv
# En Windows:
venv\Scripts\activate
# En macOS/Linux:
source venv/bin/activate
```

3. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

### Configuraci√≥n de API Keys

1. **Google Gemini API:**
   - Crear archivo `.env` en la ra√≠z del proyecto
   - Agregar tu API key: `GOOGLE_API_KEY=tu_api_key_aqui`
   - Consultar las im√°genes en `1. Estructura interna/Img/` para obtener la API key

## üõ†Ô∏è Dependencias Principales

- **google-generativeai**: Integraci√≥n con la API de Gemini
- **transformers**: Biblioteca de HuggingFace para modelos transformer
- **torch**: Framework de deep learning PyTorch
- **pandas**: Manipulaci√≥n y an√°lisis de datos
- **tiktoken**: Tokenizaci√≥n de OpenAI
- **numpy**: Computaci√≥n num√©rica

Ver `requirements.txt` para la lista completa de dependencias.

## üìö C√≥mo Usar Este Taller

### Orden Recomendado
1. Comenzar con **Estructura Interna** para entender los fundamentos
2. Continuar con **Razonamiento Interno** para comprender el funcionamiento
3. Aprender **Principios de Dise√±o de Prompts** para mejores interacciones
4. Explorar **Formato de Conversaci√≥n** para di√°logos efectivos
5. Implementar **Herramientas y Agentes** para casos de uso avanzados
6. Practicar con **API de Gemini** para integraci√≥n real
7. Experimentar con **Contenido Extra** para casos especializados

### Ejecutar los Notebooks
```bash
# Iniciar Jupyter Notebook
jupyter notebook

# O Jupyter Lab
jupyter lab
```

## üîß Funcionalidades Cubiertas

### Conceptos Fundamentales
- ‚úÖ Tokenizaci√≥n y manejo de tokens
- ‚úÖ Contexto y ventanas de atenci√≥n
- ‚úÖ Par√°metros configurables (temperatura, top-p, etc.)
- ‚úÖ Razonamiento interno de los LLMs

### T√©cnicas Avanzadas
- ‚úÖ Dise√±o optimizado de prompts
- ‚úÖ Conversaciones multi-turno
- ‚úÖ Tool calling y function calling
- ‚úÖ Implementaci√≥n de agentes

### Integraciones Pr√°cticas
- ‚úÖ API de Google Gemini
- ‚úÖ HuggingFace Hub y Transformers
- ‚úÖ Modelos locales y cuantizaci√≥n
- ‚úÖ Runtimes locales (Ollama, LM Studio)

## üéØ Objetivos de Aprendizaje

Al completar este taller, ser√°s capaz de:

1. **Comprender** la estructura interna y funcionamiento de los LLMs
2. **Dise√±ar** prompts efectivos para diferentes casos de uso
3. **Implementar** conversaciones inteligentes y agentes
4. **Integrar** APIs de LLMs en aplicaciones reales
5. **Trabajar** con modelos locales y herramientas especializadas
6. **Optimizar** el rendimiento usando par√°metros avanzados


---

**Nota:** Este taller est√° dise√±ado para ser ejecutado tanto en entornos locales como en Google Colab. Algunas celdas pueden contener c√≥digo espec√≠fico para Colab que debe ser adaptado para ejecuci√≥n local.

